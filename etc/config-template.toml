# TiKV config template
#  Human-readable big numbers: 
#   File size(based on byte): KB, MB, GB, TB, PB (or lowercase)
#    e.g.: 1_048_576 = "1MB"
#   Time(based on ms): ms, s, m, h
#    e.g.: 78_000 = "1.3m"

[server]
# set listening address.
addr = "127.0.0.1:20160"
# if not set, use addr instead. set advertise listening address for client communication.
advertise-addr = ""
# set which dsn to use, warning: default is rocksdb without persistent.
dsn = "rocksdb"
# set the path to rocksdb directory.
store = "/tmp/tikv/store"
# log level: trace, debug, info, warn, error, off.
log-level = "info"
# notify capacity, 40960 is suitable for about 7000 regions.
notify-capacity = 40960
# maximum number of messages can be processed in one tick.
messages-per-tick = 4096
# socket send/recv buffer size.
send-buffer-size = "128KB"
recv-buffer-size = "128KB"

# set store capacity, if no set, use unlimited or disk size later.
# capacity = 0 # 0 is unlimited.

[metric]
# if host applied then `udp` will be activated.
# remote statsd server address.
addr = ""
# metric prefix.
prefix = "tikv"

[raftstore]
# notify capacity, 40960 is suitable for about 7000 regions.
notify-capacity = 40960

# maximum number of messages can be processed in one tick.
messages-per-tick = 4096

# Region heartbeat tick interval (ms) for reporting to pd. 
pd-heartbeat-tick-interval = "5000ms"
# Store heartbeat tick interval (ms) for reporting to pd.
pd-store-heartbeat-tick-interval = "10000ms"

# When the region's size exceeds region-max-size, we will split the region 
# into two which the left region's size will be region-split-size or a little 
# bit smaller. 
region-max-size = "80MB"
region-split-size = "64MB"
# When region size changes exceeds region-split-check-diff, we should check 
# whether the region should be split or not. 
region-split-check-diff = "8MB"

# When a peer hasn't been active for max-peer-down-duration,
# we will consider this peer to be down and report it to pd.
max-peer-down-duration = "5m"

[raft]
# set cluster id, must greater than 0.
cluster-id = 1

[pd]
# pd endpoints 
endpoints = ""

# For detailed explanation please refer to https://github.com/facebook/rocksdb/blob/master/include/rocksdb/options.h
[rocksdb]
# compression method (if any) is used to compress a block.
#   no:     kNoCompression
#   snappy: kSnappyCompression
#   zlib:   kZlibCompression
#   bzip2:  kBZip2Compression
#   lz4:    kLZ4Compression
#   lz4hc:  kLZ4HCCompression

# per level compression
compression_per_level = "lz4:lz4:lz4:lz4:lz4:lz4:lz4"

# Amount of data to build up in memory (backed by an unsorted log
# on disk) before converting to a sorted on-disk file.
write-buffer-size = "64MB"

# The maximum number of write buffers that are built up in memory.
max-write-buffer-number = 5

# The minimum number of write buffers that will be merged together
# before writing to storage.
min-write-buffer-number-to-merge = 1

# Maximum number of concurrent background compaction jobs, submitted to
# the default LOW priority thread pool.
max-background-compactions = 4

# Control maximum total data size for base level (level 1).
max-bytes-for-level-base = "64MB"

# Target file size for compaction.
target-file-size-base = "16MB"

# If true, the database will be created if it is missing.
create-if-missing = true

# Soft limit on number of level-0 files. We start slowing down writes at this point.
level0-slowdown-writes-trigger = 12

# Maximum number of level-0 files.  We stop writes at this point.
level0-stop-writes-trigger = 16

# For detailed explanation please refer to https://github.com/facebook/rocksdb/blob/master/include/rocksdb/table.h
[rocksdb.block-based-table]
# Approximate size of user data packed per block.  Note that the 
# block size specified here corresponds to uncompressed data.
block-size = "64KB"

# block-cache used to cache uncompressed blocks, big block-cache can speed up read
block-cache-size = "1GB"

# If you're doing point lookups you definitely want to turn bloom filters on, We use
# bloom filters to avoid unnecessary disk reads. Default bits_per_key is 10, which
# yields ~1% false positive rate. Larger bits_per_key values will reduce false positive
# rate, but increase memory usage and space amplification.
bloom-filter-bits-per-key = 10

# false means one sst file one bloom filter, true means evry block has a corresponding bloom filter
block-based-bloom-filter = false

[storage]
# notify capacity of scheduler's channel
scheduler-notify-capacity = 10240

# maximum number of messages can be processed in one tick
scheduler-messages-per-tick = 1024

scheduler-concurrency = 1024

# scheduler's worker pool size
scheduler-worker-pool-size = 4
